{"keys":[{"path":["title"],"id":"title","weight":1,"src":"title","getFn":null},{"path":["body"],"id":"body","weight":1,"src":"body","getFn":null}],"records":[{"i":0,"$":{"0":{"v":"This page has not yet sprouted","n":0.408},"1":{"v":"[Dendron](https://dendron.so/) (the tool used to generate this site) lets authors selective publish content. You will see this page whenever you click on a link to an unpublished page\n\n![](https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/not-sprouted.png)","n":0.189}}},{"i":1,"$":{"0":{"v":"My Notes","n":0.707},"1":{"v":"\n## Welcome to my brain\n\nI use this wiki site and [Dendron](https://wiki.dendron.so/) to organize my thoughts about various software projects and ideas.  This tool is primarily to store my own thoughts and allow me to document my development process.  This helps me better organize these projects and plan future development.  \n\nIf others find this site interesting and possibly useful, bonus!","n":0.13}}},{"i":2,"$":{"0":{"v":"Projects","n":1},"1":{"v":"\n---\n The root page to organize my personal projects and related notes\n \n- [[projects.ndbc-reader]]\n\n- [[projects.local-recipe-server]]","n":0.258}}},{"i":3,"$":{"0":{"v":"NDBC Reader","n":0.707},"1":{"v":"\n* **Project:** \n\nThese notes are being added only after the project's complexity has reached a point where I feel the need to jot things down in order to keep track of everything in my head.  Additionally, even though these are notes to myself about my own software projects, I still write as if I'm explaining these ideas to someone else.  It's a habit I picked up when I started coding in grad school and, since it works for me, I do not feel any need to change. Alright, on to the confusing bits!\n\n---\n## Next steps\n\nThis project has been neglected since I changed jobs and have had to spend more of my free time learning different programming languages and paradigms in order to keep up.  However that comes with a bonus of exposure to more enterprise grade software architecture.  With that in mind I plan to make a more rigorous effort to use a more design pattern driven approach to the NDBC Reader package.  \n\nWhat follows is a first draft of the patterns and approaches I think would make sense to employ in this effort.\n\n* **Data Store/Data Transfer Object:** This is a more codified approach to storing the various elemets of the data that the NDBC Reader project is the focus of.  This will also encapsulate saving a Data Buoy object to disk and re-instantiating from saved data.\n* **Repository:** The repository pattern encapsulates the logic required to create, delete, and update the data.  \n* **API Services:** These services will encapsulate the logic required to make specific API requests.  \n* **Analysis Service:** This will encapsulate the rudimentary analyses that will be added to the NDBC Reader package and the Data Buoy class.\n* **Unit of Work:** This will abstract the communication between the API services (fetching data) and the repository (storing data).\n\n","n":0.058}}},{"i":4,"$":{"0":{"v":"Desired Functionalities","n":0.707},"1":{"v":"The [[projects.ndbc-reader]] software package has only a few operations, currently.  These mostly focus on retrieving and persisting data.  TThe other Functionalities are allowing access to the data stored during runtime and keeping track of data fetching operations performed and their outcome.\n\nI am documenting these Functionalities at a high level to help me plan and design the package in a more easily maintained, more highly abstracted manner.\n\n## Data Fetching\nThe primary purpose of the NDBC Data Buoy class is to simplify the fetching of monthly/annual summary data from the NDBC public websites.  These are exposed as simple `.txt` files hosted on an individual station's web page.  While there are other data archive formats and servers, I find this approach to be refreshingly direct and am sticking with it for now.\n\nA secondary data fetching action is to parse the data station web page and collect station metadata (instrumentation, location, etc.). \n\nBoth data fetching operations need to dynamically build the URLs fetched based on parameters specified at runtime.  They also need to track a failure to retrieve the data requested.  These features could be abstracted into a custom HTTP Client class.\n\nThe assignment of the returned data to the correct properties on the Data Buoy class could also be abstracted to a method designed for that purpose.\n\n## Data Persistence\nThis is the storing of the data that comprises the state of an instance of the Data Buoy class.  Ideally researchers should be able to use this package to retrieve data and then store it in a manner they find convenient so it can be analyzed later without requiring an internet connection.\n\nPresntly the only approach to data persistence/loading is writing to / reading from `.json` files.  I think it would make sense to abstract general data persistence to it's own class and work to add multiple methods including allowing users to specify database connection parameters and store individual Data Buoy data to either SQL or NoSQL databases.\n\n## Data Storage/Access\n","n":0.056}}},{"i":5,"$":{"0":{"v":"Class Split","n":0.707},"1":{"v":"\n\nThe idea to break up the `DataBuoy` class in the `NDBC` package came from a desire to separate the concerns and de-couple the functionality relating to\n1. Handle web requests/responses to and from NDBC servers\n1. Parse, store, and save station data.\n\nI imagine that there may be usecases where researchers are only interested in a limited subset of the functionality present in the `DataBuoy` class.  In that respect _I hope_ this effort will be more useful that just helping me simplify the process of modifying the existing code base.  However, it has caused me to have to rethink the way the core processes of the `DataBuoy` class due to the way in which NDBC server request functionality is tightly coupled with data parsing and storage.  Let's take a look at the new structure by examing the classes and their functionality\n\n- #### `StationWebManager`: Manages interactions with NDBC web servers.\n    - Stores constants related to web requests (e.g. `DATA_PACKAGES`, `STATION_URL`, etc.)\n    - Creates station URLs for each month/year requested and checks to see whether they exist on the NDBC server.\n    - Fetches/parses station metadata.\n    - Performs station search requests\n    - Fetches specified data packages for time periods requested\n\n- #### `DataManager`: Handles data parsing, storing, saving, and access.\n    - Performs data type asignments\n    - Parses date part columns into Python datetime values\n    - Checks for NDBC \"bad data\" flags (all digits set to 9) and replaces bad data with NumPy `NaN` value.\n    - Saves parsed data to `data` attribute.\n\n- #### `DB2`: Coordinates Subclass functionality - eventually renamed to `DataBuoy` class once all tests pass.\n    - Coordinates the use of `StationWebManager` request/response methods with `DataManager` parsing and storage methods behind a simple interface.\n    - Provide simplified data access using `@property` decorated functions.\n\n\n## Outstanding Questions:\n\nThe current implementation allows a user to make a request for a data package without specifying months or years.  In this case the function starts at the current month/year and checks for valid data, stepping back one month for reach failed request until either \n  - A valid monthly summary can be found and returned\n  - All months in the current and previous year have been queried.\n\nThe revised approach for fetching data (shown below) is designed to make a request for a single time period\n\n![[projects.ndbc-reader.class-split.station-web-manager#fetch_data]]\n","n":0.052}}},{"i":6,"$":{"0":{"v":"Station Web Manager","n":0.577},"1":{"v":"\nThe utility functionality for this class was simply copied and pasted from the original `DataBuoy` class.  These handle actions like\n - Create formatted URL strings based on parameters like `station_id`, `month`, `year`, and `data_package`.\n - Make `HEAD` requests to determine which URL string formats return a valid response.\n - All `station_search()` functionality since it's basically a web request with a lot of arguments.\n\n\n### New/Revised Functionality\nPreviously I had wrapped the requesting of data and storing inside a larger function that interated over all the distinct time periods requested for a single station and data package.  With the functionality being separated out, I need to think about how to structure these functions to achieve the separation I am looking for while still providing the functionality intended.\n\n#### `fetch_data()`\nI think this is going to be the exposed wrapper function that will encapsulate all the actions that go into making a request to the NDBC server.  Each call to this function will represent a request for a single data package for a distinct time period.  It will either return a Pandas dataframe of the raw data if the data package is available for the station and time period requested **or** it will return a string notifying the calling function that this station/data package/time period combination is not available.  Let's take a look at the steps:\n\n- Check if data type requested is in the `DATA_PACKAGES` dictionary\n    - Continue if so, raise Exception if not.\n\n- Create necessary keywords for URL string formatting\n- Choose which set of URL templates to use (month or year) based on `kwargs` passed in\n- Build URLs based on lists of template strings\n- Check URL validity based on `HEAD` request response code (`200` == `good`)\n    - If we have a good URL response, fetch data using `pandas.read_csv()` method and return resulting DataFrame.\n    - If not, return formatted string message stating the data package and time period do not appear to be available. \n","n":0.056}}},{"i":7,"$":{"0":{"v":"Local Recipe Server","n":0.577},"1":{"v":"\n## Motivation\nI love cooking and recipes.  Unfortunately I have amassed enough magazines and cookbooks that, when I want to make a particular recipe, I give up half way because finding it so laborious.  I realized I don't need hard copies, I need a searchable database with an appealing interface.  Also I've gathered more than a few Raspberry Pis and I wanted to do something cool with one (or more) of them.\n\nAlso a pet peeve of mine is how many recipe websites take up your entire phone/tablet sceen with banner adds, random stories only vaguely related to the recipe at hand, and overlapping vidoes you must carefull exit out of to avoid being redirected to some page about home loans, exciting new athletic socks, stock tips, etc.  I wanted to build an interface for viewing a recipe that was JUST THE RECIPE.\n\n## Project Definition\nThe purpose of this project is to allow users to run a server on their local (home) wireless network that does 2 things related to recipes.\n\n1. Take photographs of recipes in cookbooks or magazines and save them to the server\n1. View recipes broken down by ingredients and steps in a mobile friendly interface\n\n## [[projects.local-recipe-server.user-interfaces]]\n\nThe user interacts with this application through two distinct interfaces with separate areas of concern.\n\n* Photo upload interface [Create Recipe]\n* Recipe search/view interface [List/Retrieve Recipe]\n\n## [[projects.local-recipe-server.data-models]]\n\nA rough sketch of the data structures we will use to provide data persistence and all those nifty searching and filtering mechanisms.\n\n## [[projects.local-recipe-server.services]]\nThese are encapsulated pieces of business logic that perform the tricky custom bits of the application.\n\n## [[projects.local-recipe-server.api]]\nThe endpoints provided by the server and consumed by the client application to provide the user with CRUD capabilities for recipes.\n\n## Potential Pi Architecture\nThis will depend on the processing power and storage needs of all the above requirements.  Given the above definitions are already biting off a fair amount of development work I will likely try to keep this to a single Raspberry Pi 4B.  I'll use a 128GB flash drive for storage so that _should_ provide the capacity to store a decent amount of recipes.  While I will likely be using Docker containers to build this application (2 minimum - Client App Server, API Server), I will start with all of them running on a single Pi.  If this proves too much work I will consider tackling the whole distributed k8s mess but for now I'll try to keep it simple. \n\nWith simplicity in mind I plan to stick to just using the SQLite database.  It functions perfectly well with solid performance when accessed by a single process.  Since this application is desinged for a single user making sequential requests, this should be sufficient.\n\n## STRETCH Goal\nThis project will begin using a basic modern web site architecture using a REST API and a Vue.js front-end (my preferred framework).  This should allow for the development of an Android App that communicates with the REST API.  It's an area of development I have absolutely no experience in but it might be fun to try.\n","n":0.045}}},{"i":8,"$":{"0":{"v":"User Interfaces","n":0.707},"1":{"v":"Here I outline how I see my users interacting with this application.\n\n## [[projects.local-recipe-server.user-interfaces.landing-page]]\nWhere a user first goes to be routed to either of the interfaces listed below\n\n## [[projects.local-recipe-server.user-interfaces.create-recipe]]\nThe interface that allows the user to create/edit recipes\n\n## [[projects.local-recipe-server.user-interfaces.view-recipe]]\nThe interface that allows the user to find and view the recipe.\n","n":0.144}}},{"i":9,"$":{"0":{"v":"View Recipe","n":0.707},"1":{"v":"\nThis interface is the pay off for all the hard work of parsing and checking text representations of recipes. A simple and easily readable representation of a recipe with no ads or unrelated content displayed.\n\nIt allows for searching recipes by name or ingredient, as well as filtering by ingredients.  The use cases supported are both finding a particular recipe the user is interested in as well as allowing the user to filter saved recipes by the ingredients they have/wish to consume.\n\nThe basic views of this interface are the list of recipes and the detail view of a specific recipe.\n\n## List View\nA simple list of recipe records saved by the user.  This view will support a search bar that searches against the recipe name (possible full text search?).  Filtering by ingredients will also be supported with an autocomplete field allowing the user to look up saved ingredients.\n\n## Detail View\nThis view will present the elements of the recipe (excluding the image records).  The styling will favor clear readability over decoration. Initial design is to attempt to present all ingredients in a single view, while displaying each step individually.  Simple controls to increment steps forward and back will facilitate navigation from step to step when cooking and interactions with either a touchscreen or a mouse/keyboard must be kept to a minimum.\n","n":0.068}}},{"i":10,"$":{"0":{"v":"Landing Page","n":0.707},"1":{"v":"\nWhile so basic it barely merits mentioning, it is important to not forget this element to provide a simple means of navigating on a mobile screen size.\n\nThis landing page will simply welcome the user and direct them to either the [[projects.local-recipe-server.user-interfaces.create-recipe]] or [[projects.local-recipe-server.user-interfaces.view-recipe]] interfaces.","n":0.151}}},{"i":11,"$":{"0":{"v":"Create Recipe","n":0.707},"1":{"v":"This interface allows the user to upload photos of recipes. The saving of the file to the application server file system will trigger the parsing service to extract text from the images and assign text to data models.\n\nDepending on the amount of time necessary to perform this action, the following step may occur within the same request/response loop or require a more asynchronous approach.  \n\nOnce the parsing service returns a representation of the extracted & assigned text, this should be presented to the user in a format that asupports modification of the text and data objects assigned as well as choose whether to save the recipe or cancel. Given the les-than-perfect images likely to be gathered, it seems like assuming occasional incorrect parsing of the images into text and/or incorrect data object assignment is a safe assumption to make.\n\nTherefore this interface will consist of two views.\n\n## Upload File(s)\nThis view needs to support the loading of multiple image files and making a POST request that transmits them to the server.\n\n## Edit/Save Results\nThis view will accept the structured text output from the parsing service and present the the user the ingredients, amounts, units, and steps as editable text.  At this point only the Recipe and Image records have been saved. If the use decides to cancel at this point, those records along with the associated files will be removed.  This allows the user to abandon the attempt if they decide they want to try better photos or the work of editing the resulting parsed text does not merit the saving of the recipe.\n\nIf the user selects the save option, this will create/assign the Ingredient, Step, and associative records to complete the recipe.  It will use the current representation of the text and structure in the user interface to ensure any changes made by the user in this view is reflected in the saved records.","n":0.057}}},{"i":12,"$":{"0":{"v":"Todo","n":1},"1":{"v":"A simple list of next steps in various parts of the application implementation\n\n## Front-End\n- [x] Add `ingredient` auto-complete field with `multiple, clearable, chips`\n- [x] Add `search` sync parameter to Recipes data table and trigger recipe list API requests on change.\n\n## API\n- [x] Convert Ingredient creation in the `confirm` action to `get_or_create` to avoid duplicating ingrdient records.\n- [x] Buid out `RecipeIngredient` Serializer.\n- [x] Add serialization of related `RecipeIngredient` records to the `Recipe` serializer and return complete recipe.\n- [x] Add `ingredients` search parameter to `Recipe` endpoint\n- [x] Modify `get_queryset` method for `Recipe` endpoint to accept ingredients as a filter\n- [x] Add an Ingredient Endpoint\n\n## Data Model\n- [x] Add a unique `name` constraint to the Ingredient data model\n\n\n## Services\n- [ ] Implement text recognition\n","n":0.091}}},{"i":13,"$":{"0":{"v":"Services","n":1},"1":{"v":"\nThe service layer in this application consists of the functions required to extract the text from images uploaded by the user and translate those into representations of the data structures be to created upon saving the recipe.\n\n## [[projects.local-recipe-server.services.text-parsing]]\nHow we go from images to text\n\n## [[projects.local-recipe-server.services.text-assigment]]\nWhat we do with the text once we've got it","n":0.136}}},{"i":14,"$":{"0":{"v":"Text Parsing","n":0.707},"1":{"v":"This service function consumes an array of image files or, more likely,filepaths and returns a single corpus of extracted text.  \n\n## Tech Choices\nThis is the area of this project I am least familiar with and the most likely to take some further research and experimentation to get right.  Based on initial cursory investigations, the Python package [PyTesseract](https://pypi.org/project/pytesseract/) appears to be a good place to start.\n\n## Output\nThis is perhaps a tricky thing to define.  While not all, some recipes include a preamble or story relating to how the recipe was arrived at or the cultural provenance.  While informative and engaging, these details are not pertinent to executing the recipe.  The intent of this application is to allow users to define those recipes they care about by saving them so it is assumed the user already knows why they should care about them.  \n\nHowever, it is not the job of this service function to make those decisions.  This service exists to extract text from image files and should not be burdened by addtional business logic.  The only functionality beyond extracting text from a single image file to be included here is the appending of text from successive images to a single corpus in the case of multiple images being assocaited with a single recipe.  The recognition of line breaks, event when between successive images, will also be key as these breaks will be necessary to inform the assignment function that consumes the extracted text.\n","n":0.064}}},{"i":15,"$":{"0":{"v":"Text Assigment","n":0.707},"1":{"v":"The purpose of this function will be to consume a corpus of text and, using imperitive rules, correctly assign text to the corresponding data model, thereby constructing a recipe.\n\n## Rules\nThe application of any sort of machine learning would require such a large set of data on which to train, as well as text recognition algorithms I am not familiar with, that I think it would be easier to simply write these rules myself.  Using line breaks, bullet or numbered formatting, and the presence/absence of numbers in the text will be used to classify distinct text elemets in the corpus this function accepts as it's sole parameter.\n\n## Output\nWhile this function will break out the text provided into the representations matching the data models present in this application, it does nto create records in the database.  These data model representations will be returned in JSON string formatting.  This will alow the editing of the text by users without excessive database write operations.\n","n":0.079}}},{"i":16,"$":{"0":{"v":"ML Tasks","n":0.707},"1":{"v":"After the images are uploaded but before we can create records in our database, we have two important ML tasks to perform.  These correspond to the [[projects.local-recipe-server.services.text-parsing]] and [[projects.local-recipe-server.services.text-assigment]] [[projects.local-recipe-server.services]] we have outlined elsewhere in this doc but I am documenting the ML particulars here.\n","n":0.149}}},{"i":17,"$":{"0":{"v":"OCR","n":1},"1":{"v":"\n* **Service:** [[projects.local-recipe-server.services.text-parsing]]\n* **Core Tech:** [PyTesseract](https://pypi.org/project/pytesseract/)\n\nAccurate Optical Character Recognition (OCR) is the core of the Text Parsing service.\n\nOne of the key challenges in text recognition and parsing with recipes is the use of columnar text layouts.\n\nAnother significant challenge is the translation of ingredient lists.  The main challenge here so far is proper recognition of fractions, although list format icons can add some extra difficulty.\n\n---\n\n## Columnar Text\nAn initial attempt to to handle proper word order when extracting text from multiple columns has been attempted following [this guide](https://nanonets.com/blog/ocr-with-tesseract/).  Results have been less than ideal but introducing some imperitive coding logic may prove useful as well as refining my image pre-processing steps to provide maximum contrast while maintaining clarity.\n\n### Next Steps\n* Conduct more research into the [Open CV](https://pypi.org/project/opencv-python/) functions for detecting contours in the image for better splitting of by columns.  This should improve segmentation for text processing.\n\n---\n\n## Ingredient Lists\nOne of the most difficult to interpret characters present in ingredient lists are fractions.  Often these are translated to `Y` or `%` characters.  Numbers (depending on the font used) can also provide a significant difficulty.\n\n### Next Steps\n* Review [this tutorial](https://pyimagesearch.com/2021/08/30/detecting-and-ocring-digits-with-tesseract-and-python/) about configuring PyTesseract for digit recognition.\n* Review [this SO Question](https://stackoverflow.com/questions/55994807/why-does-pytesseract-fail-to-recognise-digits-from-image-with-darker-background) regarding improved image preprocessing.\n* Review [this Github Issue](https://github.com/tesseract-ocr/tesseract/issues/2274) regarding applying new training data to improve PyTesseract model for fraction recognition.","n":0.068}}},{"i":18,"$":{"0":{"v":"NLP","n":1},"1":{"v":"* **Service:** [[projects.local-recipe-server.services.text-assigment]]\n* **Core Tech:** [NLTK](https://www.nltk.org/index.html)\n\nNatural Language Processing (NLP) is the segmentation, tokenization, and recognition of text into meaning.  This approach is what will be used to classify portions of the recipe into Ingredients and Steps.\n\n* **Ingredients:** Usually short sentence fragments that include ingredients and amounts.  In some cases they wil also include adverbs.\n\n* **Steps:** Longer, mostly full, sentences that are often directions of what to do and contain verbs pertaining to the ingredients.\n\nThe topic of NLP is quite broad and I think my next steps will need to include working through some general tutorials as well as some more focused on identifying the components outlined above.\n\n## Next Steps\n* Review [this RealPython tutorial](https://realpython.com/nltk-nlp-python/)\n* Review [this chapter](https://www.nltk.org/book_1ed/ch05.html) of the NLTK book on categorizing and tagging words.\n\n","n":0.089}}},{"i":19,"$":{"0":{"v":"Data Models","n":0.707},"1":{"v":"## Models\nThe basic data models defined to support this application are shown below:\n\n### Ingredient\n![[projects.local-recipe-server.data-models.ingredient]]\n\n### Recipe Ingredient\n![[projects.local-recipe-server.data-models.recipe-ingredient]]\n\n### Step\n![[projects.local-recipe-server.data-models.step]]\n\n### Image\n![[projects.local-recipe-server.data-models.image]]\n\n### Recipe\n![[projects.local-recipe-server.data-models.recipe]]\n\n## Thoughts\n### Steps\nI was/am not certain about breaking out steps into their own model or using a JSON field to store an array of parsed steps. However, I have some ideas for features I want to enable in the UI and I think that separate step data objects will facilitate this.  Perhaps that could have been implemented in the business logic layer or event in the presentation layer.  I may refactor this after some work on the user-interface.","n":0.102}}},{"i":20,"$":{"0":{"v":"Step","n":1},"1":{"v":"This model represents an individual step or set of instrutions for executing the recipe.  \n\n|Field|Type|Description|\n|----|----|----|\n|**ID**| BigInt| Primary Key|\n|**RecipeID**| BigInt| FK relating to Recipe|\n|**Order**| Int | Numeric represenation of the order of the step as it relates to the Recipe|\n|**Step**|Text| Recipe directions|\n","n":0.156}}},{"i":21,"$":{"0":{"v":"Recipe","n":1},"1":{"v":"Putting it all together.\n\n|Field|Type|Description|\n|----|----|----|\n|**ID**| BigInt| Primary Key|\n|**Name**| Text | The name for this recipe|\n\n","n":0.267}}},{"i":22,"$":{"0":{"v":"Recipe Step","n":0.707},"1":{"v":"This is the associate \n","n":0.447}}},{"i":23,"$":{"0":{"v":"Recipe Ingredient","n":0.707},"1":{"v":"\nThis model is the associative entity that relates ingredients to recipes. It stores data that are unique to this relationship, i.e. quantity and unit.\n\n|Field|Type|Description|\n|----|----|----|\n|**ID**| BigInt| Primary Key\n|**RecipeID**|BigInt| FK relating to Recipe|\n|**IngredientID**|BigInt| FK relating to Ingredient|\n|**Quantity**|Int| Quantity of the ingredient in the recipe|\n|**Unit**|Text| The unit the quantity represents (e.g. cup, pinc, teaspoon)|\n","n":0.14}}},{"i":24,"$":{"0":{"v":"Ingredient","n":1},"1":{"v":"This model represents an individual ingredient used in a recipe.\n\n\n|Field|Type|Description|\n|----|----|----|\n|**ID**| BigInt| Primary Key\n|**Name**|Text| Name of the ingredient|\n\n","n":0.243}}},{"i":25,"$":{"0":{"v":"Image","n":1},"1":{"v":"\nSince it may take more than one image to contain all the text in a readable format, it is nessary to allow more than one image to be associated with a recipe.\n\n|Field|Type|Description|\n|----|----|----|\n|**ID**| BigInt| Primary Key|\n|**RecipeID**| BigInt | FK relating to Recipe|\n|**ImageFile**| FileField| Link to image file in filesystem|\n","n":0.144}}},{"i":26,"$":{"0":{"v":"API","n":1},"1":{"v":"This section defines how the client will interact with what resources in our application.  Since we offer some complex features (on the Create Recipe side), this will be more than just a simple CRUD REST API.\n\n## Create Recipe Endpoints\n\n* **POST** `/recipes` - Initial recipe creation endpoint, this will initiate the text recognition and parsing processes.\n    * **Parameters:** \n        * `images` - An array of image files representing a single recipe\n    * **Returns:**\n        * `recipe_json` - a JSON representation of the parsed recipe\n\n* **POST** `/recipes/confirm` - User confirmation/correction of parsed recipe text and organization\n    * **Parameters:**\n        * `recipe_json` - JSON representation of user confirmed/corrected recipe\n    * **Returns:**\n        * `recipe_id` - The ID identifying the recipe record created in the DB. This can also be used in a redirect to the detail view of the created recipe.\n\n---\n\n## Read Recipe Endpoints\n\n* **GET** `/recipes` - A list endpoint for viewing existing recipe records\n    * **Parameters:**\n        * `ingredients` - (Optional) filters recipes returned by relationship to the ingredient(s).\n    * **Returns:**\n        * `recipes` - A paginated list of recipes.\n* **GET** `/recipes/:id` - A detail endpoint for viewing an individual recipe.\n    * **Parameters:** - `None`\n    * **Returns:**\n        * `recipe` - A single recipe record, including ingredients and steps.\n\n* **GET** `/ingredients` - A list endpoint for ingredient records\n    * **Parameters:** - `None`\n    * **Returns:**\n        * `ingredients` - An unpaginated list of ingredients\n\n* **GET** `/recipes/:id/ingredients` - A list endpoint for ingredients related to a single recipe.\n    * **Parameters:** - `None`\n    * **Returns:**\n        * `ingredients` - A list of ingredients for a specific recipe\n\n* **GET** `/recipes/:id/steps` - A list endpoint for steps related to a single recipe.\n    * **Parameters:** - `None`\n    * **Returns:**\n        * `steps` - A list of steps to execute the recipe","n":0.059}}},{"i":27,"$":{"0":{"v":"Serializers","n":1},"1":{"v":"Because our recipes consist of multiple data models but we want to to present them as whole documents we need to coordinate the serialization.\n\n## Recipe-Ingredient Serializer\nWhen we are serializing the ingredients for a recipe, most of what we want is actually in the relationship entity.  This serializer should return the following fields as a JSON object.\n* `name` - [[projects.local-recipe-server.data-models.ingredient]] data model\n* `quantity` - [[projects.local-recipe-server.data-models.recipe-ingredient]] data model\n* `unit` - [[projects.local-recipe-server.data-models.recipe-ingredient]] data model\n\n## Recipe Serializer\nThis serializer returns the data object that the List/Detail components of our API will interact with.  It will return the following fields.\n* `title` - [[projects.local-recipe-server.data-models.recipe]] data model\n* `steps` - [[projects.local-recipe-server.data-models.recipe]] data model\n* `recipe-ingredients` - An array of serialized [[projects.local-recipe-server.data-models.recipe-ingredient]] data models\n","n":0.094}}},{"i":28,"$":{"0":{"v":"Android App Design","n":0.577},"1":{"v":"_This section is intended to capture design decisions for a potential Android application as part of the Recipes Server_\n\n---\n\nOne of the important choices to make is how much data to store locally, if at all.  The book I am working through to build Android apps is making use of the [Room API](https://developer.android.com/jetpack/androidx/releases/room) to perform CRUD operations with an SQLite DB saved locally on the Android device's file system.  This makes me start to question an entirely API reliant design.\n\n## Data Storage question\nMy question for this app is whether it would make more sense to use the local server just for performing the [[projects.local-recipe-server.services.text-parsing]] and [[projects.local-recipe-server.services.text-assigment]] functionality and store the final recipe record \nlocally or whether I should rely on the REST API entirely.  While this would simplify application design it would mean the apps functionality would entirely depend on the health and availability of a Raspberry Pi runningon my local network\n\n### Initial decision\n* Proceed with entirely REST API driven approach \n* Be prepared to transition to more data storage in the Android device itself as I become more familiar with caching and synchronizing local data with the canonical server database.","n":0.073}}}]}
