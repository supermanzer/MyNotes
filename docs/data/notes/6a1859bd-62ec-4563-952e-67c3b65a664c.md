
The utility functionality for this class was simply copied and pasted from the original `DataBuoy` class.  These handle actions like
 - Create formatted URL strings based on parameters like `station_id`, `month`, `year`, and `data_package`.
 - Make `HEAD` requests to determine which URL string formats return a valid response.
 - All `station_search()` functionality since it's basically a web request with a lot of arguments.


### New/Revised Functionality
Previously I had wrapped the requesting of data and storing inside a larger function that interated over all the distinct time periods requested for a single station and data package.  With the functionality being separated out, I need to think about how to structure these functions to achieve the separation I am looking for while still providing the functionality intended.

#### `fetch_data()`
I think this is going to be the exposed wrapper function that will encapsulate all the actions that go into making a request to the NDBC server.  Each call to this function will represent a request for a single data package for a distinct time period.  It will either return a Pandas dataframe of the raw data if the data package is available for the station and time period requested **or** it will return a string notifying the calling function that this station/data package/time period combination is not available.  Let's take a look at the steps:

- Check if data type requested is in the `DATA_PACKAGES` dictionary
    - Continue if so, raise Exception if not.

- Create necessary keywords for URL string formatting
- Choose which set of URL templates to use (month or year) based on `kwargs` passed in
- Build URLs based on lists of template strings
- Check URL validity based on `HEAD` request response code (`200` == `good`)
    - If we have a good URL response, fetch data using `pandas.read_csv()` method and return resulting DataFrame.
    - If not, return formatted string message stating the data package and time period do not appear to be available. 
